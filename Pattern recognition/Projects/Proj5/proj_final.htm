<html><head></head><body bgcolor="#ffffff"><h3> Final Project (Presentation and Report due 12/08)</h3><p>The objective of the final project is to integrate variousclassification techniques to achieve the best performance. Finalproject is a group effort. Each group can have 1-2 members. Forundergraduate students, you are required to apply all techniqueslearned in this semester. For graduate student, besides learnedtechniques in class, you are required to propose some improvementseither in computational speed or classification accuracy.<h4>Schedule</h4><ul>  <li>Milestone 1: Group formation and topic selection (due  Nov. 14). Submit through BB.  <li>Milestone 2: Background study (2-page  report due Nov. 21). Submit through BB.  <li>Final presentation (due Dec. 08). Submit through BB.  <li>Final report (due Dec. 08). Submit through BB.  </ul><h4>Options</h4>Each group can choose one topic from one of the following sources<ul>  <li>the <a href="http://archive.ics.uci.edu/ml/datasets.html">UCI MachineLearning Repository</a> <li><a href="http://www.sigkdd.org/kddcup/index.php">KDD-Cup  1997-2010</a>  <li><a href="http://www.kaggle.com/competitions">Kaggle Competitions</a>  <li>Other topics: You can select a topic yourself from other  resources with the approval from the instructor.</ul><h4>Requirement</h4><p>General steps involved in a pattern recognition problem include<ul><li>Data collection (raw data)<li>Feature derivation (how to derive features from the raw data)<li>Feature selection (dimensionality reduction, Fisher's linear discriminant or PCA)<li>Classification<ul><li>classification based on parametric or non-parametric density estimation<li>classification based on supervised learning or unsupervised learning<li>classifier fusion</ul><li>Performance evaluation<li>Feedback system</ul>In this project, you are given a dataset with data already collected and features derived (most cases). You are required to evaluate the effect of various aspects of the classification process, including but not limited to<ul><li>the effect of assuming the data is Gaussian-distributed<li>the effect of knowing the class label<li>the effect of performing dimensionality reduction<li>the effect of using PCA or FLD as dimensionality reduction technique<li>the effect of classifier fusion   </ul><p>  To be more specific, you need to at least go through the following steps:  <ul>    <li>Data normalization    <li>Dimensionality reduction    <li>Classification with the following  <ul>    <li>MPP (case 1, 2, and 3)    <li>kNN with different k's    <li>BPNN (can use open-source software package or the toolbox  comes with MATLAB)    <li>Decision tree (can use open-source software package or the toolbox  comes with MATLAB)    <li>Graduate students only: SVM (can use open-source software package or the toolbox  comes with MATLAB)    <li>clustering (kmeans, wta, kohonen)    </ul>    <li>Classifier fusion (Graduate students are required to implement three out of four fusion methods we have covered and undergraduate students need to implement two.)    <li>Evaluation (use n-fold cross validation to generate confusion matrix and ROC curve if applicable). </ul></body></html>